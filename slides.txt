=========================
The Vectorization of MOM6
=========================

:author: Marshall Ward
:description: Overview of recent efforts to vectorize MOM6
:date: 2021-04-21
:url: https://marshallward.org/ogrp2021.html
:preface:
   Introductory comments, written to slide notes


Peak Performance
================

.. math::

   W \le N \times f \times I_\text{vec}

====================    =========================
:math:`W`               FLOPs per second ("work")
:math:`N`               # of CPUs
:math:`f`               Cycles per second
:math:`I_\text{vec}`    FLOPs per cycle
====================    =========================

.. notes::

   This is a form of the so-called "iron law" of peak performance.

   It is normally written as an expression of time, rather than rate of work,
   but I think this inverse form is better suited for this discussion.

   The "work" here is written as the number of FLOPs (or floating point
   operations) per second, but it could be generalized to other units
   computational work.

   The first two terms are very straightforward: N is the number of CPUs and f
   is the clock rate, or cycles per second.  More CPUs and faster clock rate
   means more work.

   The third term here is more interesting, and is the focus here.  This
   represents the ability of the CPU to do concurrent work on a single core.


CPU Scaling
===========

.. image:: img/scaling_ocn.svg

MOM5 scaling in ACCESS-OM2


.. Fluid Dynamics Scaling
   ----------------------
   
   Tension between local (hyperbolic) solvers
   
   .. math::
   
      \frac{\partial \mathbf{u}}{\partial t}
         &= -\mathbf{u} \cdot \nabla \mathbf{u} - \nabla p + \mathbf{f} \\
   
   and global (elliptic) solvers
   
   .. math::
   
      \nabla^2 p
         &= -\nabla \cdot \left( \mathbf{u} \cdot \nabla \mathbf{u} \right)
            + \nabla \cdot \mathbf{F} \\
         &\approx \nabla \cdot \mathbf{F} \text{(?)} \\
   
   ... unless you can cheat (aka oceanography)


Clock Speed
===========

.. image:: img/clockspeed.svg
   :width: 70%

.. notes::

   This is a plot of CPU clock speeds from CPUDB.  The database goes from about
   1970 to 2014, but the situation has not changed much since then.

   The trend is clear:  Clock speed increased exponentially until about 2005.
   After that, it flattened out around 3GHz.  After that, people stopped
   talking much about clock speeds.

   This is a reflection of Moore's law (transistor rate) but is better
   explained by the breakdown of Dennard scaling.

   * P ~ f
   * P/A ~ const
   * transitor density drops exponentially => power drops too
   * => increase f to balance P

   After 2005, thermal leakage led to P >> A


Vectorization
=============

.. image:: img/specfp.svg

.. notes:::

   Main comments:

   * Despite the end of clock speed increase, FP rates continue to rise

   * But after ~2004, the rate definitely drops.  What causes it?

   * Less important: What happened in the 90s?

     This was the era of high-end vector CPUs (DEC, SPARC, etc).
     As they failed to keep up with commodity x86 chips, they left the market.

   * Even less important: The "blob" at the end is emergence of mobile chips?

   What is SPECfp?

   This is a renormalized plot of the SPECfp scores over time.

   CPUs are assigned a "score" based on their performance of a suite of
   FP-based models.  The number is somewhat arbitrary.

   Unfortunately they periodically change these tests and SPEC strongly
   discourages comparison across tests, but in the words of Jurgen Willebrand,
   no one can stop me!

   We roughly normalize along Intel trends, especially 95->2k, which is why the
   "high end" cloud permeates.

   Don't take these numbers too literally, especially my renormalization which
   I didn't properly calibrate.


Intel normalization
-------------------

.. image:: img/specfp_intel.svg

.. notes::

   Showing the normalization of Intel-based architectures.


How to improve performance?
===========================

CPU scaling
   Viable but CFL-limited

Clock speed
   Unchanged for >15 years

Vectorization
   Potential speedup?


Vector Instructions
===================

.. image:: img/avx.svg

======   ==========  =======  ===========
Instr.   Size        GFLOP/s  Obs. (Gaea)
======   ==========  =======  ===========
SSE      2 doubles   7.2      7.196
AVX      4 doubles   14.4     14.395
======   ==========  =======  ===========

.. Gaea C4 (Xeon E5-2697 v4, "Broadwell")

.. :math:`f_\text{peak} = 3.6 \times 10^9 \ \text{Hz}`


Fused-Multiply Add
==================

:math:`d \leftarrow a \times b + c`

======   ==========  =======  =======
Instr.   Op          GFLOP/s  Obs.
======   ==========  =======  =======
SSE      Add         7.2      7.196

         FMA         14.4     14.394

AVX      Add         14.4     14.395

         FMA         28.8     28.788
======   ==========  =======  =======

:math:`\text{rd}(\text{rd}(a \times b) + c)`
vs :math:`\text{rd}(a \times b + c)`



Concurrency
===========

.. image:: img/broadwell_exc.svg
   :ref: https://en.wikichip.org/wiki/File:broadwell_block_diagram.svg

2 instr. per cycle, even FMA


Peak
====

======   ==========  =======  =======
Instr.   Op          GFLOP/s  Obs.
======   ==========  =======  =======
SSE      Add         7.2      7.196

         FMA         14.4     14.394

         2x FMA      28.8     28.788

AVX      Add         14.4     14.395

         Add+Mul     28.8     28.788

         FMA         28.8     28.788

         2x FMA      57.6     57.576
======   ==========  =======  =======

 
Array Performance
=================

.. image:: img/gaea_dp_flops.svg


AMD Arrays
----------

.. image:: img/zen3_dp_flops.svg

   
Single Precision
----------------

.. image:: img/gaea_flops.svg


Array Cacheing
==============

.. image:: img/gaea_dp_flops_cached.svg


AMD Cacheing
------------

.. image:: img/zen3_dp_flops_cached.svg


Memory-bound
============

.. image:: img/gaea_dp_flops_membnd.svg


Peak Array Ops
--------------

======================  ====  ====  ====  ====
Expression              Max   L2    L3    DRAM
======================  ====  ====  ====  ====
y[:] = a x[:]           11.1  3.5   1.8   0.7
y[:] = x[:] + x[:]      12.3  3.6   1.8   0.7
y[:] = x[:] + y[:]      9.3   3.5   1.8   0.7
y[:] = a x[:] + y[:]    18.3  7.0   3.6   1.4
y[:] = a x[:] + b y[:]  23.9  10.6  5.5   2.0
y[:] = x[1:] - x[:-1]   7.0   3.4   1.8   0.7
y[:] = x[8:] - x[:-8]   9.3   3.5   1.8   0.7
======================  ====  ====  ====  ====


MOM6 sample config
==================

.. image:: img/benchmark_topo.svg
   :class: float
   :width: 35%

* 32 × 32 grid, 75 level

   - ~76k / field (~:math:`2^{16}`)
   - :math:`2^{10}` per level

* 288 steps (3 day, :math:`\Delta t = 900s`)

* "Benchmark" configuration:

   - Split barotropic

   - Smagorinsky biharmonic

   - Thermo, Wright EOS

   - Bounded Coriolis terms

   - Layered (no ALE)


Profiling with perf
===================

.. image:: img/perf_symbols.png
   :width: 80%


Profiling with perf
===================

.. image:: img/perf_lines.png
   :width: 80%


perf stat
=========

.. include:: perf.stat
   :code:


Profile Overview
================

.. image:: img/subroutine_profile.svg

(NOTE: AMD timings)


Investigation Targets
=====================

* Horizontal viscosity

* Coriolis force advection (``coradcalc``)

* Barotropic solver (``btstep``)

* Vertical viscosity (``find_coupling_coef``)

* EOS (``int_density_dz_wright``)


Horizontal Viscosity
====================

.. include:: src/MOM_hor_visc.F90
   :code:
   :start-line: 831
   :end-line: 958
   :number-lines: 831
   :data-line-numbers: 1|2-6|7-13|14-18|20-73|127


Non-vectorized code
===================

.. code:: x86asm

   │      │833    Shear_mag = sqrt(sh_xx(i,j)*sh_xx(i,j) + &
   │ 0.70 │         vaddsd   %xmm13,%xmm12,%xmm14
   │ 1.62 │         vsqrtsd  %xmm14,%xmm14,%xmm14
   │ 6.53 │         vmovsd   %xmm14,-0x8e8(%rbp)


==========  ========
``v___sd``  Serial
``v___pd``  Parallel
==========  ========


Excessive Stack
===============

.. code:: x86asm

   │      │919    Ah = MAX(MAX(CS%Ah_bg_xx(i,j), AhSm), AhLth)
   │      │         lea      (%rax,%rdx,8),%rdi
   │      │         lea      (%rdi,%rsi,1),%r8
   │ 0.39 │         vmovsd   (%r8,%r9,8),%xmm0
   │ 0.01 │         vmaxsd   -0x13f8(%rbp),%xmm0,%xmm0
   │ 2.34 │         vmaxsd   -0x13f0(%rbp),%xmm0,%xmm0
   │ 0.42 │         vmovsd   %xmm0,-0x1468(%rbp)

======   ===================
lea      Compute mem address
vmovsd   Serial move
vmaxsd   Serial max
======   ===================


Hor Visc Update
===============

TODO


Hor Visc Speedup
=====================

==========  ======   ======   =======
Platform    Old      New      Speedup
==========  ======   ======   =======
Gaea C4     2.23s    1.27s    1.75x

            (1.67)   (2.93)   

AMD @ home  1.69s    1.01s    1.67x

            (2.30)   (3.76)   
==========  ======   ======   =======


Coriolis advection
==================

.. include:: src/MOM_CoriolisAdv.F90
   :code:
   :start-line: 424
   :end-line: 686
   :number-lines: 424
   :data-line-numbers: 1|17-32|245-257


Coriolis advection
==================

.. include:: src/MOM_CoriolisAdv_vec.F90
   :code:
   :start-line: 669
   :end-line: 694
   :number-lines: 669
   :data-line-numbers: 7-20


Coriolis Speedup
================

========    ======   ======   =======
Platform    Old      New      Speedup
========    ======   ======   =======
Gaea        1.06     0.87     1.23x

            (2.79)   (3.43)   

AMD         1.11     0.64     1.74x

            (2.68)   (5.21)   
========    ======   ======   =======


Barotropic Optimization
=======================

.. code::

   LOOP BEGIN at ../../ac/../src/core/MOM_barotropic.F90(1491,26)
      remark #15389: vectorization support: reference eta_wtd(i,j) has unaligned access   [ ../      ../ac/../src/core/MOM_barotropic.F90(1492,7) ]
      remark #15381: vectorization support: unaligned access used inside loop body
      remark #15305: vectorization support: vector length 2
      remark #15399: vectorization support: unroll factor set to 2
      remark #15309: vectorization support: normalized vectorization overhead 0.300
      remark #15300: LOOP WAS VECTORIZED
      remark #15451: unmasked unaligned unit stride stores: 1
      remark #15475: --- begin vector cost summary ---
      remark #15476: scalar cost: 4
      remark #15477: vector cost: 2.500
      remark #15478: estimated potential speedup: 1.450
      remark #15488: --- end vector cost summary ---
      remark #25015: Estimate of max trip count of loop=3
   LOOP END


Barotropic Optimization...?
===========================

.. code::

   LOOP BEGIN at ../../ac/../src/core/MOM_barotropic.F90(2383,39)
      remark #25460: No loop optimizations reported
   LOOP END

.. code::

   remark #25464: Some optimizations were skipped to constrain compile
      time. Consider overriding limits (-qoverride-limits).


Barotropic Speedup
==================

Engage the Override!

========    ======   ======   =======
Platform    Old      New      Speedup
========    ======   ======   =======
Gaea        2.35     1.60     1.46x

            (1.19)   (1.74)

AMD         3.13     1.66     1.89x

            (0.89)   (1.66)
========    ======   ======   =======

Sustainable solution is to reduce size of ``btstep()``


Vertical Viscosity
==================

.. include:: src/MOM_vert_friction.F90
   :code:
   :start-line: 1248
   :end-line: 1270
   :number-lines: 1248
   :data-line-numbers: 1-23|1|23


Vertical Viscosity
==================

.. include:: src/MOM_vert_friction_vec.F90
   :code:
   :start-line: 1462
   :end-line: 1489
   :number-lines: 1462
   :data-line-numbers: 1-27|23-27


Maintain Pipelines
==================

.. image:: img/stay_on_target.gif
   :width: 50%

Keep going, even on land!


Vertical Viscosity "speedup"
============================

==================   ======   ======   ======   ======   =======
Subroutine           Old      New      Old      New      Speedup
==================   ======   ======   ======   ======   =======
vertvisc_coef        1.29     2.00     1.54     1.50     😐
find_coupling_coef   2.50     5.72     0.82     0.68     1.21x
==================   ======   ======   ======   ======   =======


Why is EOS so efficient?
========================

.. include:: src/MOM_EOS_Wright.F90
   :code:
   :start-line: 578
   :end-line: 619
   :number-lines: 578

High *arithmetic intensity*: many ops per memory access


Gaea Speedup 
============

.. image:: img/subroutine_speedup_gaea.svg


AMD Speedup
-----------

.. image:: img/subroutine_speedup.svg


Other topics
============

* Index reorder (ijk -> kij)
* Stack issues?  (Declaration reorder)
* Expression speedup


Moving Forward
==============

Development guidelines:

* Profile and identify hotspots

* Enable vectorization

* Avoid if-blocks in loops

* Keep references close together

* Reduce memory access

* Keep functions small (<2000 lines?)


Things we haven't talked about
------------------------------

* Array alignment and peel loops

* Heap vs Stack (incl. alignment)

* Pipelining

* Arithmetic Intensity


More things we haven't talked about
-----------------------------------

Multicore/node jobs

* Clock speed throttling

* Sharing the RAM bandwidth + NUMA

* perf on MPI jobs


Whence GPUs?
============

One core vs 1 GPU process

.. image:: img/p1_gpu_flops.svg


Whence GPUs?
------------

6 cores vs 6 GPU procs

.. image:: img/p6_gpu_flops.svg
